#!/usr/bin/env python3
"""
Sahibinden.com Cookie ve Ä°lan Ã‡ekici
curl_cffi ile Chrome TLS parmak izi taklidi
"""

from curl_cffi import requests
from bs4 import BeautifulSoup
import json
import sys
from datetime import datetime, timezone

ANA_URL = "https://www.sahibinden.com"
HEDEF_URL = "https://www.sahibinden.com/ekran-karti-masaustu"


def log(mesaj):
    """Zaman damgalÄ± log"""
    ts = datetime.now().strftime("%H:%M:%S")
    print(f"[{ts}] {mesaj}", flush=True)


def main():
    log("ğŸš€ Script baÅŸladÄ±")

    tum_cookieler = {}

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1ï¸âƒ£ ANA SAYFA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log("â‘  Ana sayfa isteÄŸi atÄ±lÄ±yor...")

    try:
        r1 = requests.get(
            ANA_URL,
            impersonate="chrome",  # Otomatik en gÃ¼ncel Chrome taklidi
            timeout=30
        )
        log(f"   âœ“ Status: {r1.status_code}")
        log(f"   âœ“ HTML Boyutu: {len(r1.text):,} karakter")

        # Cookie'leri topluyoruz
        tum_cookieler.update(dict(r1.cookies))
        log(f"   âœ“ Cookie: {len(tum_cookieler)} adet")

    except Exception as e:
        log(f"   âŒ Ana sayfa hatasÄ±: {e}")
        sys.exit(1)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2ï¸âƒ£ HEDEF SAYFA (Ekran KartlarÄ±)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log("â‘¡ Hedef sayfa isteÄŸi atÄ±lÄ±yor...")

    try:
        r2 = requests.get(
            HEDEF_URL,
            impersonate="chrome",
            cookies=tum_cookieler,
            headers={"Referer": ANA_URL},
            timeout=30
        )
        log(f"   âœ“ Status: {r2.status_code}")
        log(f"   âœ“ HTML Boyutu: {len(r2.text):,} karakter")

        # Cookie'leri gÃ¼ncelle
        tum_cookieler.update(dict(r2.cookies))

    except Exception as e:
        log(f"   âŒ Hedef sayfa hatasÄ±: {e}")
        sys.exit(1)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3ï¸âƒ£ DOSYALARI KAYDET
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # HTML kaydet
    with open("sayfa.html", "w", encoding="utf-8") as f:
        f.write(r2.text)
    log("   âœ“ sayfa.html kaydedildi")

    # Cookie kaydet
    with open("cookies.json", "w", encoding="utf-8") as f:
        json.dump({
            "cookies": tum_cookieler,
            "toplam": len(tum_cookieler),
            "isimler": sorted(tum_cookieler.keys()),
            "tarih": datetime.now(timezone.utc).isoformat()
        }, f, indent=2, ensure_ascii=False)
    log("   âœ“ cookies.json kaydedildi")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4ï¸âƒ£ Ä°LANLARI PARSE ET
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log("â‘¢ Ä°lanlar parse ediliyor...")

    soup = BeautifulSoup(r2.text, "html.parser")
    ilanlar = []

    for item in soup.select("tr.searchResultsItem"):
        baslik_el = item.select_one("a.classifiedTitle")
        fiyat_el = item.select_one("td.searchResultsPriceValue span")
        konum_el = item.select_one("td.searchResultsLocationValue")
        
        if baslik_el:
            ilanlar.append({
                "baslik": baslik_el.get_text(strip=True),
                "url": "https://www.sahibinden.com" + baslik_el.get("href", ""),
                "fiyat": fiyat_el.get_text(strip=True) if fiyat_el else "",
                "konum": konum_el.get_text(" ", strip=True) if konum_el else ""
            })

    # Ä°lanlarÄ± kaydet
    with open("ilanlar.json", "w", encoding="utf-8") as f:
        json.dump({
            "toplam": len(ilanlar),
            "tarih": datetime.now(timezone.utc).isoformat(),
            "ilanlar": ilanlar[:50]  # Ä°lk 50 ilan
        }, f, indent=2, ensure_ascii=False)

    log(f"   âœ“ {len(ilanlar)} ilan bulundu")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5ï¸âƒ£ Ã–ZET
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log("\n" + "â•" * 50)
    log("  Ã–ZET")
    log("â•" * 50)
    log(f"  HTML Boyutu : {len(r2.text):,} karakter")
    log(f"  Cookie      : {len(tum_cookieler)} adet")
    log(f"  Ä°lan        : {len(ilanlar)} adet")
    log(f"â•" * 50)

    # BaÅŸarÄ± kontrolÃ¼
    if len(r2.text) < 50000:
        log("\nâš ï¸  UYARI: HTML boyutu kÃ¼Ã§Ã¼k, muhtemelen engellendin")
        log("   sayfa.html dosyasÄ±nÄ± kontrol et")
        sys.exit(1)

    if len(ilanlar) == 0:
        log("\nâš ï¸  UYARI: Ä°lan bulunamadÄ±")
        log("   HTML yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir")

    log("\nâœ… TAMAMLANDI")


if __name__ == "__main__":
    main()
